\documentclass{article}  
\usepackage{amsmath}
\author{Ethan Sherbondy}
\date{\today}
\title{Problem Set 3: Networks and Gene Regulation}
 
\begin{document}  
\maketitle  
\section{Bayesian Decision Theory}  

\section{Gibbs Sampling For Motif Discovery}

My Gibbs sampling algorithm is modeled after the algorithm
described in Chapter 12.2 of \textit{An Introduction to Bioinformatcs Algorithms}. It also makes use of relative entropy to weigh the random choice of a starting position (step 5 as described on page 413). I make use of pseudocounts for my profile matrix. I do \textbf{not} use the log-of-odds when calculating my l-mer probabilities, as Clojure handles extremely small decimal numbers fairly well.

My metric for convergence is a value referred to in the code as the \textit{cutoff}. For simplicity, I say the algorithm has converged when cutoff rounds go by without an increase in the maximum-probability l-mer. I've arbitrarily set the cutoff to be 20 rounds in the current implementation, but it can easily be adjusted. If I had more time, it would be fun to explore using simulated annealing instead of my naive approach.

Despite using relative entropy, my solution seems to perform poorly when the AT/GC ratio is non-uniform. This suggests to me that I am not making proper use of the relative-entropy equation.

Regardless, below is a table summarizing the most frequent 10-mer motifs discovered across the four datasets provided:

\begin{center}
  \begin{tabular}{ | l | l | l | l | l | l }
    \hline
    Data 1     & Data 2      & Data 3      & Data 4 \\ \hline
    ATTCGAATTC & GTCTACTACT  & AAAAAAAAAA  & AAAAAAAAAA \\ \hline
    TCGAATTCCC & CTACTACTCA  & TTTTTTTTTT  & AACAAAAAAA \\ \hline
    TTCGAATTCC & TCATATAACA  & AAAAAAAAGA  & TTTTTTTTTT \\ \hline
    CGAATTCGAA & CTGTCTACTA  & AAAAAAAACA  & AAAAAAAAAT \\ \hline
    AATTCGAATT & TCTCTTAAGA  & TTGTATATAT  & ATAAATAAAT \\
    \hline
  \end{tabular}
\end{center}

As you can see, the results for data 3 and 4 are likely not actual motifs.

\end{document}